{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e413743f-4fde-45bb-bd15-3955f33aab6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Results:\n",
      "                                 Model  Chi2\n",
      "0                  Logistic Regression  0.96\n",
      "1      Support Vector Machine (Linear)  0.95\n",
      "2  Support Vector Machine (Non-Linear)  0.97\n",
      "3                  K-Nearest Neighbors  0.89\n",
      "4                          Naive Bayes  0.86\n",
      "5                        Decision Tree  0.94\n",
      "6                        Random Forest  0.98\n",
      "\n",
      "Regression Results:\n",
      "                                 Model        R2\n",
      "0                    Linear Regression  0.600951\n",
      "1      Support Vector Machine (Linear)  0.585310\n",
      "2  Support Vector Machine (Non-Linear)  0.803288\n",
      "3                        Decision Tree  0.739583\n",
      "4                        Random Forest  0.893316\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "\n",
    "def selectkbest(indep_X, dep_Y, n):\n",
    "    test = SelectKBest(score_func=chi2, k=n)\n",
    "    fit1 = test.fit(indep_X, dep_Y)\n",
    "    selectk_features = fit1.transform(indep_X)\n",
    "    return selectk_features\n",
    "\n",
    "def split_scalar(indep_X, dep_Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size=0.25, random_state=0)\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def evaluate_classification_models(X_train, y_train, X_test, y_test):\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(random_state=0),\n",
    "        'Support Vector Machine (Linear)': SVC(kernel='linear', random_state=0),\n",
    "        'Support Vector Machine (Non-Linear)': SVC(kernel='rbf', random_state=0),\n",
    "        'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "        'Naive Bayes': GaussianNB(),\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=0),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "    }\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        if name == 'Random Forest':\n",
    "            param_grid = {'n_estimators': [50, 100, 150]}  # Define hyperparameters for grid search\n",
    "            grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            best_model = grid_search.best_estimator_\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            results[name] = accuracy_score(y_test, y_pred)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            results[name] = accuracy_score(y_test, y_pred)\n",
    "    return results\n",
    "\n",
    "def evaluate_regression_models(X_train, y_train, X_test, y_test):\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Support Vector Machine (Linear)': SVR(kernel='linear'),\n",
    "        'Support Vector Machine (Non-Linear)': SVR(kernel='rbf'),\n",
    "        'Decision Tree': DecisionTreeRegressor(random_state=0),\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=10, random_state=0)\n",
    "    }\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        if name == 'Random Forest':\n",
    "            param_grid = {'n_estimators': [50, 100, 150]}  # Define hyperparameters for grid search\n",
    "            grid_search = GridSearchCV(model, param_grid, cv=5, scoring='r2')\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            best_model = grid_search.best_estimator_\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            results[name] = r2_score(y_test, y_pred)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            results[name] = r2_score(y_test, y_pred)\n",
    "    return results\n",
    "\n",
    "def selectk_evaluation(dataset_file, target_col, n_features):\n",
    "    dataset = pd.read_csv(dataset_file)\n",
    "    #df_encoded = pd.get_dummies(dataset, drop_first=True)\n",
    "    \n",
    "    indep_X = dataset.drop(target_col, axis=1)\n",
    "    dep_Y = dataset[target_col]\n",
    "    \n",
    "    kbest_features = selectkbest(indep_X, dep_Y, n_features)\n",
    "    X_train, X_test, y_train, y_test = split_scalar(kbest_features, dep_Y)\n",
    "    \n",
    "    classification_results = evaluate_classification_models(X_train, y_train, X_test, y_test)\n",
    "    regression_results = evaluate_regression_models(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    return classification_results, regression_results\n",
    "\n",
    "# Change these parameters as needed\n",
    "dataset_file = \"finaldata.csv\"\n",
    "target_col = \"Possible\"\n",
    "n_features = 5\n",
    "\n",
    "class_results, reg_results = selectk_evaluation(dataset_file, target_col, n_features)\n",
    "\n",
    "# Display results in a table\n",
    "classification_df = pd.DataFrame(class_results.items(), columns=['Model', 'Chi2'])\n",
    "regression_df = pd.DataFrame(reg_results.items(), columns=['Model', 'R2'])\n",
    "\n",
    "print(\"Classification Results:\")\n",
    "print(classification_df)\n",
    "\n",
    "print(\"\\nRegression Results:\")\n",
    "print(regression_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f6285-846b-4575-b7eb-d3b0dc30add6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
